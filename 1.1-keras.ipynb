{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section :1 - Adapting Architectures for resolution change:\n",
    "\n",
    "Q-1.1 – Please refer to the “Aggregated Residual Transformations for Deep Neural Networks” (ResNeXt) architecture (paper, code). The task is to adapt this architecture to work with 64x64 images for training and prediction. Please use the down-sampled ImageNet(link) as the train/test dataset. You can either directly adapt the Lua reference implementation from FAIR or re-implement it in your preferred framework. \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Paper Link : https://arxiv.org/pdf/1611.05431.pdf\n",
    "\n",
    "Dataset Link : http://image-net.org/small/download.php\n",
    "\n",
    "Git Link : https://github.com/facebookresearch/ResNeXt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective : \n",
    "\n",
    "To adapt this architecture to work with 64x64 images for training and prediction\n",
    "\n",
    "### Experiment : \n",
    "\n",
    "There are two ways to solve this problem :\n",
    "\n",
    "* Resize the images in the dataset to (224 * 224) dimensions and then use the same model.\n",
    "* We need to modify the image default size defined in the model in the below link.\n",
    "https://github.com/facebookresearch/ResNeXt/blob/833a3849c982c1d562b6e552c0a6f305c420ebde/models/init.lua#L44\n",
    "\n",
    "\n",
    "\n",
    "### Experiments tried : \n",
    "\n",
    "I setup the model and ran it on the defined parameters.\n",
    "\n",
    "* th main.lua -dataset cifar10 -bottleneckType resnext_C -depth 29 -baseWidth 64 -cardinality 16 -weightDecay 5e-4 -batchSize 32 -nGPU 2 -LR 0.025 -nThreads 8 -shareGradInput true\n",
    "\n",
    "\n",
    "I changed the image size, defined in the model and ran the model again with the updated arguements.\n",
    "\n",
    "* th main.lua -dataset cifar10 -bottleneckType resnext_C -depth 29 -baseWidth 64 -cardinality 16 -weightDecay 5e-4 -batchSize 32 -nGPU 2 -LR 0.025 -nThreads 8 -shareGradInput true\n",
    "\n",
    "* th main.lua -data datasets/imagenet -dataset imagenet -bottleneckType resnext_C -depth 50 -baseWidth 64 -cardinality 1 -weightDecay 5e-4 -batchSize 32 -nGPU 1 -LR 0.025 -nThreads 8 -shareGradInput true\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kears implementation\n",
    "\n",
    "* Source \n",
    "* https://github.com/nitish11/Kaggle-submissions-image-classification/tree/master/cifar-10-keras\n",
    "* https://github.com/raghakot/keras-resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import six\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Activation, Dense, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.merge import add\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ReduceLROnPlateau, CSVLogger, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def _bn_relu(input):\n",
    "    \"\"\"Helper to build a BN -> relu block\n",
    "    \"\"\"\n",
    "    norm = BatchNormalization(axis=CHANNEL_AXIS)(input)\n",
    "    return Activation(\"relu\")(norm)\n",
    "\n",
    "\n",
    "def _conv_bn_relu(**conv_params):\n",
    "    \"\"\"Helper to build a conv -> BN -> relu block\n",
    "    \"\"\"\n",
    "    filters = conv_params[\"filters\"]\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
    "\n",
    "    def f(input):\n",
    "        conv = Conv2D(filters=filters, kernel_size=kernel_size,\n",
    "                      strides=strides, padding=padding,\n",
    "                      kernel_initializer=kernel_initializer,\n",
    "                      kernel_regularizer=kernel_regularizer)(input)\n",
    "        return _bn_relu(conv)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def _bn_relu_conv(**conv_params):\n",
    "    \"\"\"Helper to build a BN -> relu -> conv block.\n",
    "    This is an improved scheme proposed in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "    \"\"\"\n",
    "    filters = conv_params[\"filters\"]\n",
    "    kernel_size = conv_params[\"kernel_size\"]\n",
    "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
    "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
    "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
    "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
    "\n",
    "    def f(input):\n",
    "        activation = _bn_relu(input)\n",
    "        return Conv2D(filters=filters, kernel_size=kernel_size,\n",
    "                      strides=strides, padding=padding,\n",
    "                      kernel_initializer=kernel_initializer,\n",
    "                      kernel_regularizer=kernel_regularizer)(activation)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def _shortcut(input, residual):\n",
    "    \"\"\"Adds a shortcut between input and residual block and merges them with \"sum\"\n",
    "    \"\"\"\n",
    "    # Expand channels of shortcut to match residual.\n",
    "    # Stride appropriately to match residual (width, height)\n",
    "    # Should be int if network architecture is correctly configured.\n",
    "    input_shape = K.int_shape(input)\n",
    "    residual_shape = K.int_shape(residual)\n",
    "    stride_width = int(round(input_shape[ROW_AXIS] / residual_shape[ROW_AXIS]))\n",
    "    stride_height = int(round(input_shape[COL_AXIS] / residual_shape[COL_AXIS]))\n",
    "    equal_channels = input_shape[CHANNEL_AXIS] == residual_shape[CHANNEL_AXIS]\n",
    "\n",
    "    shortcut = input\n",
    "    # 1 X 1 conv if shape is different. Else identity.\n",
    "    if stride_width > 1 or stride_height > 1 or not equal_channels:\n",
    "        shortcut = Conv2D(filters=residual_shape[CHANNEL_AXIS],\n",
    "                          kernel_size=(1, 1),\n",
    "                          strides=(stride_width, stride_height),\n",
    "                          padding=\"valid\",\n",
    "                          kernel_initializer=\"he_normal\",\n",
    "                          kernel_regularizer=l2(0.0001))(input)\n",
    "\n",
    "    return add([shortcut, residual])\n",
    "\n",
    "\n",
    "def _residual_block(block_function, filters, repetitions, is_first_layer=False):\n",
    "    \"\"\"Builds a residual block with repeating bottleneck blocks.\n",
    "    \"\"\"\n",
    "    def f(input):\n",
    "        for i in range(repetitions):\n",
    "            init_strides = (1, 1)\n",
    "            if i == 0 and not is_first_layer:\n",
    "                init_strides = (2, 2)\n",
    "            input = block_function(filters=filters, init_strides=init_strides,\n",
    "                                   is_first_block_of_first_layer=(is_first_layer and i == 0))(input)\n",
    "        return input\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def basic_block(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
    "    \"\"\"Basic 3 X 3 convolution blocks for use on resnets with layers <= 34.\n",
    "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "    \"\"\"\n",
    "    def f(input):\n",
    "\n",
    "        if is_first_block_of_first_layer:\n",
    "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
    "            conv1 = Conv2D(filters=filters, kernel_size=(3, 3),\n",
    "                           strides=init_strides,\n",
    "                           padding=\"same\",\n",
    "                           kernel_initializer=\"he_normal\",\n",
    "                           kernel_regularizer=l2(1e-4))(input)\n",
    "        else:\n",
    "            conv1 = _bn_relu_conv(filters=filters, kernel_size=(3, 3),\n",
    "                                  strides=init_strides)(input)\n",
    "\n",
    "        residual = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv1)\n",
    "        return _shortcut(input, residual)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def bottleneck(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
    "    \"\"\"Bottleneck architecture for > 34 layer resnet.\n",
    "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
    "\n",
    "    Returns:\n",
    "        A final conv layer of filters * 4\n",
    "    \"\"\"\n",
    "    def f(input):\n",
    "\n",
    "        if is_first_block_of_first_layer:\n",
    "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
    "            conv_1_1 = Conv2D(filters=filters, kernel_size=(1, 1),\n",
    "                              strides=init_strides,\n",
    "                              padding=\"same\",\n",
    "                              kernel_initializer=\"he_normal\",\n",
    "                              kernel_regularizer=l2(1e-4))(input)\n",
    "        else:\n",
    "            conv_1_1 = _bn_relu_conv(filters=filters, kernel_size=(3, 3),\n",
    "                                     strides=init_strides)(input)\n",
    "\n",
    "        conv_3_3 = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv_1_1)\n",
    "        residual = _bn_relu_conv(filters=filters * 4, kernel_size=(1, 1))(conv_3_3)\n",
    "        return _shortcut(input, residual)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def _handle_dim_ordering():\n",
    "    global ROW_AXIS\n",
    "    global COL_AXIS\n",
    "    global CHANNEL_AXIS\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        ROW_AXIS = 1\n",
    "        COL_AXIS = 2\n",
    "        CHANNEL_AXIS = 3\n",
    "    else:\n",
    "        CHANNEL_AXIS = 1\n",
    "        ROW_AXIS = 2\n",
    "        COL_AXIS = 3\n",
    "\n",
    "\n",
    "def _get_block(identifier):\n",
    "    if isinstance(identifier, six.string_types):\n",
    "        res = globals().get(identifier)\n",
    "        if not res:\n",
    "            raise ValueError('Invalid {}'.format(identifier))\n",
    "        return res\n",
    "    return identifier\n",
    "\n",
    "\n",
    "class ResnetBuilder(object):\n",
    "    @staticmethod\n",
    "    def build(input_shape, num_outputs, block_fn, repetitions):\n",
    "        \"\"\"Builds a custom ResNet like architecture.\n",
    "\n",
    "        Args:\n",
    "            input_shape: The input shape in the form (nb_channels, nb_rows, nb_cols)\n",
    "            num_outputs: The number of outputs at final softmax layer\n",
    "            block_fn: The block function to use. This is either `basic_block` or `bottleneck`.\n",
    "                The original paper used basic_block for layers < 50\n",
    "            repetitions: Number of repetitions of various block units.\n",
    "                At each block unit, the number of filters are doubled and the input size is halved\n",
    "\n",
    "        Returns:\n",
    "            The keras `Model`.\n",
    "        \"\"\"\n",
    "        _handle_dim_ordering()\n",
    "        if len(input_shape) != 3:\n",
    "            raise Exception(\"Input shape should be a tuple (nb_channels, nb_rows, nb_cols)\")\n",
    "\n",
    "        # Permute dimension order if necessary\n",
    "        if K.image_dim_ordering() == 'tf':\n",
    "            input_shape = (input_shape[1], input_shape[2], input_shape[0])\n",
    "\n",
    "        print \"Input Shape : \",input_shape\n",
    "        # Load function from str if needed.\n",
    "        block_fn = _get_block(block_fn)\n",
    "\n",
    "        input = Input(shape=input_shape)\n",
    "        conv1 = _conv_bn_relu(filters=64, kernel_size=(7, 7), strides=(2, 2))(input)\n",
    "        pool1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")(conv1)\n",
    "\n",
    "        block = pool1\n",
    "        filters = 64\n",
    "        for i, r in enumerate(repetitions):\n",
    "            block = _residual_block(block_fn, filters=filters, repetitions=r, is_first_layer=(i == 0))(block)\n",
    "            filters *= 2\n",
    "\n",
    "        # Last activation\n",
    "        block = _bn_relu(block)\n",
    "\n",
    "        # Classifier block\n",
    "        block_shape = K.int_shape(block)\n",
    "        pool2 = AveragePooling2D(pool_size=(block_shape[ROW_AXIS], block_shape[COL_AXIS]),\n",
    "                                 strides=(1, 1))(block)\n",
    "        flatten1 = Flatten()(pool2)\n",
    "        dense = Dense(units=num_outputs, kernel_initializer=\"he_normal\",\n",
    "                      activation=\"softmax\")(flatten1)\n",
    "\n",
    "        model = Model(inputs=input, outputs=dense)\n",
    "        return model\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_18(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [2, 2, 2, 2])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_34(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [3, 4, 6, 3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_50(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 6, 3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_101(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 23, 3])\n",
    "\n",
    "    @staticmethod\n",
    "    def build_resnet_152(input_shape, num_outputs):\n",
    "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 8, 36, 3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#To read the training data and create training set for keras model \n",
    "def prepare_data(no_classes,dataset_path,num_of_channels,image_width,image_height):\n",
    "    print \"===Setting the data ===\"\n",
    "    class_names = os.listdir(dataset_path)\n",
    "\n",
    "    #Calculate the number of the images in the dataset\n",
    "    N=0\n",
    "    for p_name in class_names:\n",
    "        i_path = dataset_path + \"/\"+p_name \n",
    "        i_count = len(os.listdir(i_path))\n",
    "        N += i_count\n",
    "\n",
    "    # Training Data\n",
    "    X_train = np.zeros((N, image_width, image_height, num_of_channels), dtype=np.uint8)\n",
    "    y_train = np.zeros((N,no_classes), dtype=np.int64)\n",
    "\n",
    "    index = 0\n",
    "    data_count =0\n",
    "    data_class = 0\n",
    "\n",
    "    #class list and Images to read from directory\n",
    "    for class_index,class_name in enumerate(class_names):\n",
    "\n",
    "        images_path = dataset_path + \"/\"+class_name \n",
    "        images_count = len(os.listdir(images_path))\n",
    "        label_data = np.zeros((no_classes), dtype=np.uint8)\n",
    "        data_class += 1\n",
    "        data_count += images_count\n",
    "\n",
    "        print \"= class name\",class_name\n",
    "        images_filenames = glob.glob(images_path + '/*.png')\n",
    "\n",
    "        # Solution #1\n",
    "        # train_images = [np.array(cv2.resize(cv2.imread(f),(image_width,image_height))) for f in images_filenames]\n",
    "\n",
    "        train_images = [np.array(cv2.imread(f)) for f in images_filenames]\n",
    "        num_of_images = len(train_images) \n",
    "        train_index = index+num_of_images \n",
    "\n",
    "        X_train[index:train_index] = train_images\n",
    "        #Labelling data\n",
    "        label_data[data_class-1] = 1\n",
    "        y_train[index:train_index] = label_data\n",
    "\n",
    "        index += num_of_images\n",
    "        if data_class == no_classes:\n",
    "            break\n",
    "\n",
    "    print \"Xtrain shape :- \" + str(np.shape(X_train)) \n",
    "    print \"Ytrain shape :- \" + str(np.shape(y_train)) \n",
    "    print \"==Number of classs taken into data :\" + str(data_class) \n",
    "\n",
    "    return X_train,y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Setting the data ===\n",
      "= class name n02130308\n",
      "= class name n02165456\n",
      "= class name n01632458\n",
      "= class name n01798484\n",
      "= class name n01968897\n",
      "= class name n01582220\n",
      "= class name n02112350\n",
      "= class name n01532829\n",
      "= class name n02091831\n",
      "= class name n02102040\n",
      "Xtrain shape :- (500, 64, 64, 3)\n",
      "Ytrain shape :- (500, 10)\n",
      "==Number of classs taken into data :10\n",
      "===Setting the data ===\n",
      "= class name n02130308\n",
      "= class name n02165456\n",
      "= class name n01632458\n",
      "= class name n01798484\n",
      "= class name n01968897\n",
      "= class name n01582220\n",
      "= class name n02112350\n",
      "= class name n01532829\n",
      "= class name n02091831\n",
      "= class name n02102040\n",
      "Xtrain shape :- (500, 64, 64, 3)\n",
      "Ytrain shape :- (500, 10)\n",
      "==Number of classs taken into data :10\n",
      "Input Shape :  (64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\n",
    "early_stopper = EarlyStopping(min_delta=0.001, patience=10)\n",
    "csv_logger = CSVLogger('imagenet.csv')\n",
    "\n",
    "batch_size = 32\n",
    "nb_classes = 10\n",
    "nb_epoch = 200\n",
    "data_augmentation = True\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 64, 64\n",
    "img_channels = 3\n",
    "\n",
    "#Loading the imagenet dataset\n",
    "X_train,Y_train = prepare_data(nb_classes,'./test_data',img_channels,img_rows,img_cols)\n",
    "X_test,Y_test = prepare_data(nb_classes,'./test_data',img_channels,img_rows,img_cols)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# subtract mean and normalize\n",
    "mean_image = np.mean(X_train, axis=0)\n",
    "X_train -= mean_image\n",
    "X_test -= mean_image\n",
    "X_train /= 128.\n",
    "X_test /= 128.\n",
    "\n",
    "model = ResnetBuilder.build_resnet_18((img_channels, img_rows, img_cols), nb_classes)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_2 (InputLayer)             (None, 64, 64, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)               (None, 32, 32, 64)    9472                                         \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNor (None, 32, 32, 64)    256                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_18 (Activation)       (None, 32, 32, 64)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)   (None, 16, 16, 64)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)               (None, 16, 16, 64)    36928                                        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNor (None, 16, 16, 64)    256                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_19 (Activation)       (None, 16, 16, 64)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)               (None, 16, 16, 64)    36928                                        \n",
      "____________________________________________________________________________________________________\n",
      "add_9 (Add)                      (None, 16, 16, 64)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNor (None, 16, 16, 64)    256                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_20 (Activation)       (None, 16, 16, 64)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)               (None, 16, 16, 64)    36928                                        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNor (None, 16, 16, 64)    256                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_21 (Activation)       (None, 16, 16, 64)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)               (None, 16, 16, 64)    36928                                        \n",
      "____________________________________________________________________________________________________\n",
      "add_10 (Add)                     (None, 16, 16, 64)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNor (None, 16, 16, 64)    256                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_22 (Activation)       (None, 16, 16, 64)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)               (None, 8, 8, 128)     73856                                        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNor (None, 8, 8, 128)     512                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_23 (Activation)       (None, 8, 8, 128)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)               (None, 8, 8, 128)     8320                                         \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)               (None, 8, 8, 128)     147584                                       \n",
      "____________________________________________________________________________________________________\n",
      "add_11 (Add)                     (None, 8, 8, 128)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNor (None, 8, 8, 128)     512                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_24 (Activation)       (None, 8, 8, 128)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)               (None, 8, 8, 128)     147584                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNor (None, 8, 8, 128)     512                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_25 (Activation)       (None, 8, 8, 128)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)               (None, 8, 8, 128)     147584                                       \n",
      "____________________________________________________________________________________________________\n",
      "add_12 (Add)                     (None, 8, 8, 128)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNor (None, 8, 8, 128)     512                                          \n",
      "____________________________________________________________________________________________________\n",
      "activation_26 (Activation)       (None, 8, 8, 128)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)               (None, 4, 4, 256)     295168                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNor (None, 4, 4, 256)     1024                                         \n",
      "____________________________________________________________________________________________________\n",
      "activation_27 (Activation)       (None, 4, 4, 256)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)               (None, 4, 4, 256)     33024                                        \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)               (None, 4, 4, 256)     590080                                       \n",
      "____________________________________________________________________________________________________\n",
      "add_13 (Add)                     (None, 4, 4, 256)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNor (None, 4, 4, 256)     1024                                         \n",
      "____________________________________________________________________________________________________\n",
      "activation_28 (Activation)       (None, 4, 4, 256)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)               (None, 4, 4, 256)     590080                                       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNor (None, 4, 4, 256)     1024                                         \n",
      "____________________________________________________________________________________________________\n",
      "activation_29 (Activation)       (None, 4, 4, 256)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)               (None, 4, 4, 256)     590080                                       \n",
      "____________________________________________________________________________________________________\n",
      "add_14 (Add)                     (None, 4, 4, 256)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNor (None, 4, 4, 256)     1024                                         \n",
      "____________________________________________________________________________________________________\n",
      "activation_30 (Activation)       (None, 4, 4, 256)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)               (None, 2, 2, 512)     1180160                                      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNor (None, 2, 2, 512)     2048                                         \n",
      "____________________________________________________________________________________________________\n",
      "activation_31 (Activation)       (None, 2, 2, 512)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)               (None, 2, 2, 512)     131584                                       \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)               (None, 2, 2, 512)     2359808                                      \n",
      "____________________________________________________________________________________________________\n",
      "add_15 (Add)                     (None, 2, 2, 512)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNor (None, 2, 2, 512)     2048                                         \n",
      "____________________________________________________________________________________________________\n",
      "activation_32 (Activation)       (None, 2, 2, 512)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)               (None, 2, 2, 512)     2359808                                      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNor (None, 2, 2, 512)     2048                                         \n",
      "____________________________________________________________________________________________________\n",
      "activation_33 (Activation)       (None, 2, 2, 512)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)               (None, 2, 2, 512)     2359808                                      \n",
      "____________________________________________________________________________________________________\n",
      "add_16 (Add)                     (None, 2, 2, 512)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNor (None, 2, 2, 512)     2048                                         \n",
      "____________________________________________________________________________________________________\n",
      "activation_34 (Activation)       (None, 2, 2, 512)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePool (None, 1, 1, 512)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 512)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 10)            5130                                         \n",
      "====================================================================================================\n",
      "Total params: 11,192,458.0\n",
      "Trainable params: 11,184,650.0\n",
      "Non-trainable params: 7,808.0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Summary of model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n",
      "Epoch 1/200\n",
      "15/15 [==============================] - 49s - loss: 3.3218 - acc: 0.1146 - val_loss: 15.2203 - val_acc: 0.1000\n",
      "Epoch 2/200\n",
      " 9/15 [=================>............] - ETA: 16s - loss: 3.1054 - acc: 0.1479"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(X_train, Y_train,\n",
    "              batch_size=batch_size,\n",
    "              nb_epoch=nb_epoch,\n",
    "              validation_data=(X_test, Y_test),\n",
    "              shuffle=True,\n",
    "              callbacks=[lr_reducer, early_stopper, csv_logger])\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "    # Compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(X_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),\n",
    "                        steps_per_epoch=X_train.shape[0] // batch_size,\n",
    "                        validation_data=(X_test, Y_test),\n",
    "                        epochs=nb_epoch, verbose=1, max_q_size=100,\n",
    "                        callbacks=[lr_reducer, early_stopper, csv_logger])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
